#!/bin/bash

set -e

echo "ğŸ” Checking for Ollama..."

if ! command -v ollama &> /dev/null; then
  echo "â¬‡ï¸ Ollama not found, installing via Homebrew..."
  if ! command -v brew &> /dev/null; then
    echo "âŒ Homebrew is required but not installed. Please install it first: https://brew.sh"
    exit 1
  fi
  brew install ollama
else
  echo "âœ… Ollama already installed."
fi

echo "ğŸš¦ Checking if Ollama server is running..."
if ! lsof -i :11434 | grep LISTEN &> /dev/null; then
  echo "ğŸš€ Starting Ollama server in background..."
  nohup ollama serve > ollama.log 2>&1 &
  sleep 2  # Give it time to bind
else
  echo "âœ… Ollama server already running."
fi

echo "ğŸŒ Verifying API is reachable..."
if curl -s http://localhost:11434 | grep -q "Ollama is running"; then
  echo "âœ… Ollama API is up!"
else
  echo "âŒ Ollama API failed to respond. Something's wrong."
  exit 1
fi

echo "ğŸ“¦ Pulling supported Ollama models from Python Enum..."
MODELS=$(python3 bosworth/ollama_models.py)

for model in $MODELS; do
  echo "  â¤ Pulling $model..."
  ollama pull "$model"
done

echo "ğŸ§ª Verifying models are registered..."
ollama list | grep -E "llama3.2|mistral"

echo "ğŸ‰ Setup complete!"
echo "â¡ï¸ Models 'llama3.2' and 'mistral' are ready to use via http://localhost:11434"